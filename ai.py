import os
import dspy
from typing import Optional
from pydantic import BaseModel
from dotenv import load_dotenv

load_dotenv()


lm = dspy.LM("openai/gpt-4o", api_key=os.getenv('OPENAI_API_KEY'), temperature=0)
dspy.configure(lm=lm)
 
def ai(user_prompt: str, system_prompt: Optional[str] = None):
    class QA(dspy.Signature):
        __doc__ = system_prompt
        
        user_prompt: str = dspy.InputField(desc="The user's request.")
        response: str = dspy.OutputField(desc="The text response generated by the language model.")
        
    predict = dspy.Predict(QA)
    return predict(user_prompt=user_prompt).response
    
if __name__ == "__main__":
    # Test ai basic text response
    print("Testing with system and user prompts:")
    response = ai(
        system_prompt="You are a helpful geography assistant.",
        user_prompt="What is the capital of France?",
    )
    print(response)
    print("\n---\n")
    # Test ai with Pydantic model
    class TestResponse(BaseModel):
        answer: str
        confidence: float
    
    print("Testing with Pydantic model:")
    response = ai(
        "What is 2+2?",
        response_model=TestResponse
    )
    print(f"Answer: {response.answer}")
    print(f"Confidence: {response.confidence}")
    
    from models import Experiment
    # Test with complex Experiment model
    print("\nTesting with Experiment Pydantic model:")
    response = ai(
        "Generate an experiment idea for building a neural network.",
        response_model=Experiment
    )
    print(f"Description: {response.description}")
    print(f"Importance: {response.importance}")
    print(f"Hypothesis: {response.hypothesis}")
    print(f"Reasoning: {', '.join(response.reasoning)}")
    print(f"Scope: {response.scope}")
    print(f"Limitations: {', '.join(response.limitations)}")
    print(f"Unknowns: {', '.join(response.unknowns)}")
    print(f"Prerequisites: {', '.join(response.prerequisites)}")
    